# DL2-DreMa: Investigating Synthetic Data (DreMa) for Robotic Manipulation Policies

This repository contains the code and findings for a research project investigating the impact of synthetic demonstrations generated by DreMa (Dream to Manipulate) on the performance of learning-based robotic manipulation policies, specifically PerAct and 3D Diffuser Actor.

## Table of Contents
1.  [Introduction](#1.-introduction)
2.  [Exposition of Strengths, Weaknesses, and Potential](#2.-exposition-of-strengths-weaknesses-and-potential)
3.  [Our Novel Contribution](#our-novel-contribution)
4.  [Results](#results)
5.  [How to Run the Code](#how-to-run-the-code)
6.  [Conclusion](#conclusion)
7.  [Student Contributions](#student-contributions)

## 1. Introduction

This project investigate the efficacy of using synthetic data, specifically from the DreMa framework [1], to augment training datasets for robotic manipulation policies. The core idea is to evaluate whether DREMA's physically consistent synthetic demonstrations can improve the performance of existing visuomotor policies like PerAct [2] and 3D Diffuser Actor [3] on tasks from the RLBench [4] benchmark, particularly the "slide block to color target" task.

### Paper Analysis: DREMA, PerAct, and 3D Diffuser Actor

*   **DREMA (Dream to Manipulate: Compositional world models empowering robot imitation learning with imagination) [1]:** DreMa, by Barcellona et al. (2024), proposes a framework for generating large-scale, physically plausible synthetic demonstrations for robot imitation learning. It leverages Gaussian splatting for scene representation, physics simulation for realistic interactions, and equivariant transformations to create diverse and consistent data. The goal is to overcome the costly and time-consuming process of collecting real-world demonstrations.

*   **PerAct (Perceiver-Actor: A Multi-task Transformer for Robotic Manipulation) [2]:** Shridhar et al. (2022) introduce PerAct, a Transformer-based architecture that processes 3D visual voxel grids to predict 6-DOF actions for various manipulation tasks. It's known for its ability to handle multi-task learning and generalize from relatively few demonstrations. Our project aimed to reproduce PerAct and assess its performance when augmented with DreMa data.

*   **3D Diffuser Actor (Policy Diffusion with 3D Scene Representations) [3]:** Ke et al. (2024) propose 3D Diffuser Actor, a policy that learns to predict actions via a diffusion model operating on 3D scene representations. Diffusion models have shown promise in generating high-quality, complex outputs, and this work applies them to robot action generation. We extended the evaluation of DreMa to this more recent policy.

The key components of these papers revolve around leveraging 3D visual information for robust policy learning and, in DreMa's case, efficiently scaling data generation. Our project investigates the potential of combining these approaches.

### Related Work

The challenge of data acquisition in robotics has spurred research in several areas. **World models** [5] aim to learn a model of the environment to facilitate planning or policy learning, with generative (e.g., UniSIM [6], RoboDreamer [7]) and recurrent state-space models (e.g., DayDreamer [8]) being prominent. DreMa builds upon these by focusing on physically consistent data generation through simulation. **Data augmentation** techniques, common in computer vision [9], have also been adapted for robotics, including generating counterfactual transitions [10] and applying invariant transformations [11] to existing trajectories to enhance dataset diversity. Furthermore, **Test-Time Adaptation (TTA)** [12] seeks to adapt pre-trained policies to novel test environments without retraining, offering a path to improved generalization—an avenue we explored preliminarily. Our work sits at the intersection, using a simulation-based framework (DreMa) for data augmentation and investigating its impact on 3D-aware policies.

## 2. Exposition of Strengths, Weaknesses, and Potential

The motivation for this project stemmed from several observations:

*   **Strengths & Potential of DREMA:**
    *   **Scalable Data Generation:** The primary appeal of DreMa is its potential to generate vast amounts of diverse, physically plausible synthetic data, mitigating the bottleneck of real-world data collection.
    *   **Improved Generalization:** Augmenting training sets with such data could lead to policies that are more robust and generalize better to unseen scenarios and dynamic conditions.
    *   **Reduced Real-World Burden:** If successful, synthetic data could significantly reduce the need for costly and labor-intensive real-world demonstrations.

*   **Identified Weaknesses/Challenges (in the field and our project context):**
    *   **Reproducibility Crisis in Robotics:** A significant portion of our effort highlighted the reproducibility challenges in robotics research. Complex software dependencies (PyRep, CoppeliaSim, PyBullet), tight coupling with specific OS/GPU drivers, and difficulties with headless environments (like HPC clusters) make reproducing and extending prior work non-trivial.
    *   **Maintenance of Codebases:** Older or less actively maintained codebases (like PerAct and PyRep in our experience) can have unresolved issues that hinder straightforward reuse and evaluation.
    *   **Full Evaluation Barriers:** Infrastructure limitations (e.g., headless HPC systems incompatible with GUI-dependent simulators like CoppeliaSim for evaluation) can prevent a complete assessment of policy performance, forcing reliance on proxy metrics like training/validation losses which may not correlate perfectly with task success.

This project was motivated by the desire to validate DreMa's promising approach on other advanced policies (3D Diffuser Actor) and to gain first-hand experience with the practicalities of implementing and extending such systems, especially concerning the often-understated reproducibility and deployment hurdles.

## 3. Our Novel Contribution

Our contributions in this project are:
1.  **Extended Evaluation of DREMA to 3D Diffuser Actor:** We were the first, to our knowledge, to evaluate the impact of DreMa-generated synthetic data on the 3D Diffuser Actor policy, providing new insights into the benefits and potential trade-offs of this data augmentation strategy.
2.  **Documentation of Reproducibility Challenges:** A significant outcome is the detailed documentation of the practical difficulties encountered in setting up, training, and evaluating these complex robotic learning systems, particularly on headless HPC environments. This includes issues with software dependencies, containerization, and simulator compatibility.
3.  **Exploration of Test-Time Adaptation (TTA):** We initiated an exploration of a TTA pipeline leveraging DreMa for scene reconstruction at inference and a Vision-Language Model (VLM) for task monitoring. While rendering and integration challenges prevented full implementation, this outlines a promising future research direction.
4.  **Recommendations for Improved Reproducibility:** Based on our experiences, we propose concrete recommendations for the robotics research community to improve reproducibility, such as providing HPC-compatible containers (e.g., Apptainer) and more self-contained experimental setups.

## 4. Results

Our experiments yielded mixed but insightful results:

*   **PerAct:**
    *   We successfully trained PerAct for 100,000 steps on a combined RLBench and DREMA dataset for the "slide block to color target" task (excluding the wrist camera due to malfunctions, aligning with DREMA authors' setup).
    *   Training curves (see Appendix, Figure 2 in project report) show learning progress.
    *   However, full evaluation was not possible due to CoppeliaSim's incompatibility with the headless Snellius HPC environment, even with VirtualGL.

*   **3D Diffuser Actor:**
    *   We trained 3D Diffuser Actor in two settings: (1) RLBench data only, and (2) RLBench + DreMa data, both for 100,000 steps.
    *   **Performance (from validation metrics):**
        | Data                 | Position Accuracy (% L2 err < 0.01) | Rotation Accuracy (% L1 err < 0.025) |
        | -------------------- | ----------------------------------- | ------------------------------------ |
        | RLBench              | 77.4%                               | 75.6%                                |
        | DREMA + RLBench      | **78.0%**                           | 63.2%                                |
    *   Incorporating DreMa data led to a **improvement in position accuracy** but a **decrease in rotation accuracy**.
    *   Training and validation curves (see Appendix, Figure 1 in the project report) provide further details.
    *   Full test deployment and task success evaluation were similarly hindered by CoppeliaSim limitations. Our result above are thus not fully indicative of the potential benefits brought to 3D Diffuser Actor by DreMa's generated data.

*   **Test-Time Adaptation (TTA):**
    *   Our attempt to build a TTA pipeline using DreMa for scene reconstruction and a VLM for task monitoring was halted by critical obstacles:
        *   Data formatting issues for DreMa's multi-view input requirements from RLBench test data.
        *   Python version conflicts.
        *   Instability of CoppeliaSim's OpenGL rendering in headless/mixed setups.
    *   These incompatibilities prevented a functional merged environment but highlighted crucial areas for future work in system-level compatibility and robust containerization.

The findings underscore that while synthetic data holds promise, its integration is not always straightforward, and single-task training metrics may not fully capture true policy performance. The pervasive reproducibility and deployment challenges in robotics are also critical takeaways.

## 5. How to Run the Code

This project relies heavily on specific versions of simulators and libraries. We used Apptainer (formerly Singularity) for containerization, suitable for HPC environments like Snellius.

### General Setup (HPC & Apptainer)

*   All experiments were designed to run on an HPC cluster (Snellius) using Apptainer.
*   Apptainer definition files (`.def`) are built into Singularity Image Format (`.sif`) containers.
*   Ensure you have Apptainer installed if running locally, or access to an HPC environment that supports it.
*   Data is expected to be on a shared file system accessible by compute nodes (e.g., `/scratch-shared/` on Snellius).

### 3D Diffuser Actor

The primary codebase for 3D Diffuser Actor experiments can be found within this repository, adapted from the original.

#### Building the Container
To build the Apptainer SIF container for 3D Diffuser Actor using the definition file at `snellius_env/diffuser_actor_jammy.def`:
```bash
sbatch snellius_env/build_diffuser_actor_jammy.job
```
This will generate `diffuser_actor_jammy.sif` in the project root.

#### Data Preparation
Follows the original 3D Diffuser Actor's [data preparation readme](https://github.com/nickgkan/3d_diffuser_actor/blob/e3efaa9a5f7f6fe40de5511ca645295f7b0230b9/docs/DATA_PREPARATION_RLBENCH.md).
The steps are: 1. Rerender, 2. Rearrange, 3. Package.

*   **Full Repackaging (including rerender - requires functional CoppeliaSim):**
    ```bash
    # This job attempts all steps but may fail on headless HPC due to CoppeliaSim
    sbatch snellius_env/3d_diff_data_repackaging.job
    ```
*   **Repackaging (rearrange & package only - no CoppeliaSim needed):**
    This is useful if you have pre-rendered data or are using DREMA's provided point clouds.
    ```bash
    sbatch snellius_env/3d_diff_data_repackaging_only.job
    ```
*   **Rearranging Test Data:**
    To prepare RLBench test data for evaluation:
    ```bash
    export HOST_INPUT_FOR_REPACKAGE_ROOT=/path/to/original_rlbench_test_data 
    # e.g., /scratch-shared/tmp.lUdVGE8VOd/3d_diff_packaged/test
    sbatch snellius_env/3d_diff_test_data_rearrange.job
    ```

*   **Creating the Mixed (RLBench + DreMa) Dataset:**
    1.  Unzip DreMa and RLBench episode data.
    2.  Merge them into a single directory.
    3.  **Crucially, rename DreMa episodes (e.g., `episode0023`) to match RLBench format (`episode23`)** to ensure compatibility with repackaging scripts.
    4.  Use `snellius_env/3d_diff_data_repackaging_only.job` to prepare the merged dataset.

#### Training and Evaluating

*   **Training:**
    1.  Export the environment variable `HOST_PERACT_PACKAGED_DATA_ROOT` to point to your prepared training data.
        *   For original RLBench data: `export HOST_PERACT_PACKAGED_DATA_ROOT="/scratch-shared/tmp.lUdVGE8VOd/Peract_onetask_repackaged"`
        *   For mixed (RLBench + DreMa) data: `export HOST_PERACT_PACKAGED_DATA_ROOT="/scratch-shared/tmp.lUdVGE8VOd/mixed_onetask_repackaged"`
    2.  Modify `snellius_env/3d_diff_training.job` if needed (e.g., to change `HOST_PERACT_PACKAGED_DATA_ROOT`).
    3.  Run the training job:
        ```bash
        sbatch snellius_env/3d_diff_training.job
        ```
    *(Note: We did not upscale images for a fair comparison with PerAct).*

*   **Evaluating:**
    1.  Edit `snellius_env/3d_diff_eval.job` and set `HOST_CHECKPOINT_FILE_PATH` to your saved checkpoint file.
    2.  Run the evaluation job:
        ```bash
        sbatch snellius_env/3d_diff_eval.job
        ```
    *(Disclaimer: Full evaluation using this script was hindered on Snellius due to the container's lack of CoppeliaSim support in a headless environment.)*

### PerAct

#### Building the container
To build the Apptainer SIF container, use the DEF file defined at `build_peract_jammy.def`. To run it, execute `sbatch snellius_env/build_peract_jammy.job`. This will generate the SIF container at the project root named `peract_jammy.sif`.

#### Data preparation
To get the data you have to first fetch the RLBench data and then generate the DreMa data. The second step can be done following COPPELIA.md which can be found at DreMa's official repository. After loading both data, merge them in order to train a model that includes both types of data. This should happen at the level of the folder named 'episodes'.

#### Training
To train the model, run `sbatch snellius_env/train_everything.job`, but first make sure to alter the data path inside the same file. The path should go to a depth just before the task name (in this case slide_block_to_color_target). For example, if the path is `/home/user/scratch/slide_block_to_color_target/all_variations/episodes...` then the given path should be `/home/user/scratch/`.

#### Evaluation
To evaluate the model, run `sbatch snellius_env/validate_peract.job`, but first make sure to alter the data path inside the same file. The path should go to a depth just before the task name (in this case slide_block_to_color_target). For example, if the path is `/home/user/scratch/slide_block_to_color_target/all_variations/episodes...` then the given path should be `/home/user/scratch/`. In addition, make sure to give the correct path for the trained weights and create the corresponding folders in which the evaluation will store the results. Details are given at the README.md located at PerAct's official repository. Note that evaluation scripts are not running correctly for PerAct as it is an open issue both for PerAct and this repository.


### Test-Time Adaptation (TTA)

This is in an incomplete stage and is reported only for documentation purposes. The corresponding files can be found under the 'TTA' folder.

## 6. Conclusion

Our project reproduced and extended evaluations of robotic manipulation policies using synthetic data from DreMa. Critically, our work underscores the significant reproducibility and deployment challenges prevalent in robotics research. Complex software dependencies, OS and graphics incompatibilities, and problematic headless rendering for simulators like CoppeliaSim severely impeded full policy evaluation and the development of a test-time adaptation pipeline.

We urge the research community to prioritize reproducibility by:
*   Meticulously specifying all system prerequisites.
*   Providing HPC-compatible container images (e.g., Apptainer, as Docker is often restricted on HPCs).
*   Developing more self-contained experimental setups that minimize reliance on legacy or system-specific software.

## 7. Student Contributions

This project was a collaborative effort by:

*   **Spiros Baxevanakis:** Literature review, 3D Diffuser Actor data management, 3D Diffuser Actor experiments, report writing
*   **Federica Valeau:** Literature review, PerAct reproduction and training, data management, report writing
*   **Lester Yang:** Initial setup, data management, 3D Diffuser Actor reproduction and training, Github maintainance, HPC containerization
*   **Platon Karageorgis:** PerAct reproduction and training, data management, TTA exploration, HPC containerization, report writing

---
**References:**

[1] Leonardo Barcellona, Andrii Zadaianchuk, Davide Allegro, Samuele Papa, Stefano Ghidoni, and Efstratios Gavves. Dream to manipulate: Compositional world models empowering robot imitation learning with imagination. CoRR, abs/2412.14957, 2024. doi: 10.48550/ARXIV.2412.14957. URL https://doi.org/10.48550/arXiv.2412.14957.

[2] Mohit Shridhar, Lucas Manuelli, and Dieter Fox. Perceiver-actor: A multi-task transformer for robotic manipulation. In Karen Liu, Dana Kulic, and Jeffrey Ichnowski, editors, Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand, volume 205 of Proceedings of Machine Learning Research, pages 785–799. PMLR, 2022. URL https://proceedings.mlr.press/v205/shridhar23a.html.

[3] Tsung-Wei Ke, Nikolaos Gkanatsios, and Katerina Fragkiadaki. 3d diffuser actor: Policy diffusion with 3d scene representations. In Pulkit Agrawal, Oliver Kroemer, and Wolfram Burgard, editors, Conference on Robot Learning, 6-9 November 2024, Munich, Germany, volume 270 of Proceedings of Machine Learning Research, pages 1949–1974. PMLR, 2024. URL https://proceedings.mlr.press/v270/ke25a.html.

[4] Stephen James, Zicong Ma, David Rovick Arrojo, and Andrew J. Davison. Rlbench: The robot learning benchmark & learning environment. IEEE Robotics Autom. Lett., 5(2):3019–3026, 2020. doi: 10.1109/LRA.2020.2974707. URL https://doi.org/10.1109/LRA.2020.2974707.

[5] David Ha and Jürgen Schmidhuber. World models. 2018. doi: 10.5281/ZENODO.1207631. URL https://zenodo.org/record/1207631.

[6] Mengjiao Yang, Yilun Du, Kamyar Ghasemipour, Jonathan Tompson, Dale Schuurmans, and Pieter Abbeel. Learning interactive real-world simulators. arXiv preprint arXiv:2310.06114, 2023.

[7] Siyuan Zhou, Yilun Du, Jiaben Chen, Yandong Li, Dit-Yan Yeung, and Chuang Gan. Robodreamer: Learning compositional world models for robot imagination. arXiv preprint arXiv:2404.12377, 2024.

[8] Philipp Wu, Alejandro Escontrela, Danijar Hafner, Pieter Abbeel, and Ken Goldberg. Daydreamer: World models for physical robot learning. In Conference on robot learning, pages 2226 2240. PMLR, 2023.

[9] Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. Imagenet classification with deep convolutional neural networks. Neural Information Processing Systems, 25, 01 2012. doi: 10.1145/3065386.

[10] Silviu Pitis, Elliot Creager, Ajay Mandlekar, and Animesh Garg. Mocoda: Model-based counterfactual data augmentation, 2022. URL https://arxiv.org/abs/2210.11287.

[11] Nicholas E. Corrado and Josiah P. Hanna. Understanding when dynamics-invariant data augmentations benefit model-free reinforcement learning updates, 2024. URL https://arxiv.org/abs/
2310.17786.

[12] Junha Song, Kwanyong Park, InKyu Shin, Sanghyun Woo, Chaoning Zhang, and In So Kweon. Test-time adaptation in the dynamic world with compound domain knowledge management, 2023. URL https://arxiv.org/abs/2212.08356.


